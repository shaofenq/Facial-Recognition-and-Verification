{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaofenq/Facial-Recognition-and-Verification/blob/main/hw6_q1_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LcqeztRmhNWo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "try:\n",
        "    from termcolor import cprint\n",
        "except ImportError:\n",
        "    cprint = None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/HW6 code and data-20221118T190940Z-001.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDNCxUr6Oc79",
        "outputId": "cd661318-5114-4a41-d24e-2266b70e4e82"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/HW6 code and data-20221118T190940Z-001.zip\n",
            "  inflating: HW6 code and data/hw6_q1_template.ipynb  \n",
            "  inflating: HW6 code and data/fmnist_test_labels.npy  \n",
            "  inflating: HW6 code and data/fmnist_train_labels.npy  \n",
            "  inflating: HW6 code and data/nyt_vocab.txt  \n",
            "  inflating: HW6 code and data/nyt_data.txt  \n",
            "  inflating: HW6 code and data/fmnist_train_images.npy  \n",
            "  inflating: HW6 code and data/fmnist_test_images.npy  \n",
            "  inflating: HW6 code and data/hw6_q3_template.ipynb  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yQLclL8hor6"
      },
      "outputs": [],
      "source": [
        "cfg = {\n",
        "    'lr': 0.01,\n",
        "    'weight_decay': 0.0001,\n",
        "    'momentum': 0.9,\n",
        "    'nesterov': True,\n",
        "    'epochs': 20,\n",
        "    'batch_size': 64,\n",
        "    'log_every': 1,\n",
        "    'val_every': 1,\n",
        "    'num_workers': 1,\n",
        "    'patience': 5,\n",
        "    'lr_decay': 0.5\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check shapes\n",
        "DATA_PATH = '/content/HW6 code and data'\n",
        "x_path = DATA_PATH + \"/\" + \"fmnist_\" + \"train\" +  \"_images.npy\" \n",
        "y_path = DATA_PATH + \"/\" + \"fmnist_\" + \"train\" +  \"_labels.npy\" \n",
        "X = np.load(x_path)\n",
        "Y = np.load(y_path)\n",
        "max, min = X[0].max(), X[0].min()\n",
        "n = (X[0] - min)/(max-min)\n",
        "#print(n)\n"
      ],
      "metadata": {
        "id": "XDf_lK2ll6l9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAQ0DQ8HhYMn"
      },
      "outputs": [],
      "source": [
        "# Q1.1.2 b\n",
        "# TODO: Define your data path (the directory containing the 4 np array files)\n",
        "DATA_PATH = '/content/HW6 code and data'\n",
        "\n",
        "class FMNIST(Dataset):\n",
        "    def __init__(self, set_name):\n",
        "        super(FMNIST, self).__init__()\n",
        "        # TODO: Retrieve all the images and the labels, and store them\n",
        "        # as class variables. Maintaing any other class variables that \n",
        "        # you might need for the other class methods. Note that the \n",
        "        # methods depends on the set (train or test) and thus maintaining\n",
        "        # that is essential.\n",
        "        self.X_path = DATA_PATH + \"/\" + \"fmnist_\" + set_name +  \"_images.npy\" \n",
        "        self.Y_path = DATA_PATH + \"/\" + \"fmnist_\" + set_name +  \"_labels.npy\"\n",
        "\n",
        "        self.X = np.load(self.X_path)\n",
        "        self.Y = np.load(self.Y_path)\n",
        "\n",
        "        pass\n",
        "    \n",
        "    def __len__(self):\n",
        "        # TODO: Complete this\n",
        "        return self.X.shape[0]\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # TODO: Complete this\n",
        "        # get the normalized image [0,1]\n",
        "        max, min = max(self.X[index]), min(self.X[index])\n",
        "        normalized_X = (self.X[index] - min)/(max - min)\n",
        "        return (torch.tensor(normalized_X),torch.tensor(self.Y[index]))\n",
        "\n",
        "def get_data_loader(set_name):\n",
        "    # TODO: Create the dataset class tailored to the set (train or test)\n",
        "    # provided as argument. Use it to create a dataloader. Use the appropriate\n",
        "    # hyper-parameters from cfg\n",
        "    dataset = FMNIST(set_name)\n",
        "    return DataLoader(dataset, shuffle=True, batch_size= cfg[\"batch_size\"], num_workers = cfg[\"num_workers\"],pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1.1.2 a\n",
        "\n",
        "__len__ and __getitem__ methods are frequentyly used when the dataloader grab batch of data and then feed into our model, length method lets the loader control the batch numbers and __getitem__ helps locate specific data sample corresponding to certian index. Together, they can let dataloader not only assemble data into batches and locate them accurately by using indexes."
      ],
      "metadata": {
        "id": "9QGgYtqep9mG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aT3VXcWuhkd8"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def xavier_init(param):\n",
        "    # NOTE: Not for Vanilla Classifier\n",
        "    # TODO: Complete this to initialize the weights\n",
        "    raise NotImplementedError\n",
        "\n",
        "def zero_init(param):\n",
        "    # NOTE: Not for Vanilla Classifier\n",
        "    # TODO: Complete this to initialize the weights\n",
        "    raise NotImplementedError\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        # TODO: Define the model architecture here\n",
        "        raise NotImplementedError\n",
        "\n",
        "        # NOTE: Not for Vanilla Classsifier\n",
        "        # TODO: Initalize weights by calling the\n",
        "        # init_weights method\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        # NOTE: Not for Vanilla Classsifier\n",
        "        # TODO: Initalize weights by calling by using the\n",
        "        # appropriate initialization function\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Define the forward function of your model\n",
        "        raise NotImplementedError\n",
        "    \n",
        "    def save(self, ckpt_path):\n",
        "        # TODO: Save the checkpoint of the model\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def load(self, ckpt_path):\n",
        "        # TODO: Load the checkpoint of the model\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYLdNQZVhcl0"
      },
      "outputs": [],
      "source": [
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "def log_print(text, color=None, on_color=None, attrs=None):\n",
        "    if cprint is not None:\n",
        "        cprint(text, color=color, on_color=on_color, attrs=attrs)\n",
        "    else:\n",
        "        print(text)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    #TODO: Returns the current Learning Rate being used by\n",
        "    # the optimizer\n",
        "    raise NotImplementedError\n",
        "\n",
        "'''\n",
        "Use the average meter to keep track of average of the loss or \n",
        "the test accuracy! Just call the update function, providing the\n",
        "quantities being added, and the counts being added\n",
        "'''\n",
        "class AvgMeter():\n",
        "    def __init__(self):\n",
        "        self.qty = 0\n",
        "        self.cnt = 0\n",
        "    \n",
        "    def update(self, increment, count):\n",
        "        self.qty += increment\n",
        "        self.cnt += count\n",
        "    \n",
        "    def get_avg(self):\n",
        "        if self.cnt == 0:\n",
        "            return 0\n",
        "        else: \n",
        "            return self.qty/self.cnt\n",
        "\n",
        "\n",
        "def run(net, epoch, loader, optimizer, criterion, logger, scheduler, train=True):\n",
        "    # TODO: Performs a pass over data in the provided loader\n",
        "    \n",
        "    # TODO: Initalize the different Avg Meters for tracking loss and accuracy (if test)\n",
        "\n",
        "    # TODO: Iterate over the loader and find the loss. Calculate the loss and based on which\n",
        "    # set is being provided update you model. Also keep track of the accuracy if we are running\n",
        "    # on the test set.\n",
        "\n",
        "    # TODO: Log the training/testing loss using tensorboard. \n",
        "    \n",
        "    # TODO: return the average loss, and the accuracy (if test set)\n",
        "    raise NotImplementedError\n",
        "        \n",
        "\n",
        "def train(net, train_loader, test_loader, logger):    \n",
        "    # TODO: Define the SGD optimizer here. Use hyper-parameters from cfg\n",
        "    optimizer = None\n",
        "    # TODO: Define the cross entropy criterion (Objective Function) here\n",
        "    criterion = None\n",
        "    # TODO: Define the ReduceLROnPlateau scheduler for annealing the learning rate. Use hyper-parameters from cfg\n",
        "    scheduler = None\n",
        "\n",
        "    for i in range(cfg['epochs']):\n",
        "        # Run the network on the entire train dataset. Return the average train loss\n",
        "        # Note that we don't have to calculate the accuracy on the train set.\n",
        "        loss, _ = run(net, i, train_loader, optimizer, criterion, logger, scheduler)\n",
        "\n",
        "        # TODO: Get the current learning rate by calling get_lr() and log it to tensorboard\n",
        "        \n",
        "        # Logs the training loss on the screen, while training\n",
        "        if i % cfg['log_every'] == 0:\n",
        "            log_text = \"Epoch: [%d/%d], Training Loss:%2f\" % (i, cfg['epochs'], loss)\n",
        "            log_print(log_text, color='green', attrs=['bold'])\n",
        "\n",
        "        # Evaluate our model and add visualizations on tensorboard\n",
        "        if i % cfg['val_every'] == 0:\n",
        "            # TODO: HINT - you might need to perform some step before and after running the network\n",
        "            # on the test set\n",
        "            # Run the network on the test set, and get the loss and accuracy on the test set \n",
        "            loss, acc = run(net, i, test_loader, optimizer, criterion, logger, scheduler, train=False)\n",
        "            log_text = \"Epoch: %d, Test Accuracy:%2f\" % (i, acc*100.0)\n",
        "            log_print(log_text, color='red', attrs=['bold'])\n",
        "\n",
        "            # TODO: Perform a step on the scheduler, while using the Accuracy on the test set\n",
        "            \n",
        "            # TODO: Use tensorboard to log the Test Accuracy and also to perform visualization of the \n",
        "            # 2 weights of the first layer of the network!\n",
        "            raise NotImplementedError\n",
        "\n",
        "\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCPLRjoNh6q2"
      },
      "outputs": [],
      "source": [
        "net = None\n",
        "\n",
        "# TODO: Create a tensorboard object for logging\n",
        "writer = None\n",
        "\n",
        "# TODO: Create train data loader\n",
        "train_loader = None\n",
        "\n",
        "# TODO: Create test data loader\n",
        "test_loader = None\n",
        "\n",
        "# Run the training!\n",
        "train(net, train_loader, test_loader, writer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaQ40CIOsaE2"
      },
      "outputs": [],
      "source": [
        "# For tensorboard visualization. Feel free to modify this code based on your local machine.\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}